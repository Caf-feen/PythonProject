{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJmcM4M19wK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5796bf61-bc76-43c0-bc3d-5c126dc33ba7"
      },
      "source": [
        "# This will create a tool that trains several machine learning models to perform the task of classifying online reviews.\n",
        "import json, requests, sklearn.tree, sklearn.metrics, sklearn.neighbors, sklearn.neural_network, math, sklearn.model_selection, textblob, nltk, joblib\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "response = requests.get(\"https://dgoldberg.sdsu.edu/515/appliance_reviews.json\")\n",
        "\n",
        "if response:\n",
        "    data = json.loads(response.text)\n",
        "    \n",
        "    unique = []\n",
        "    #The code below will append and create a list of all the unique words \n",
        "    for line in data:\n",
        "        review = line[\"Review\"]\n",
        "        review_word = textblob.TextBlob(review)\n",
        "\n",
        "        for word in review_word.words:\n",
        "\n",
        "            if word.lower() not in unique:\n",
        "                unique.append(word.lower())\n",
        "    #Below are the counters for narrowing down which words are relevant for classification \n",
        "    total = []            \n",
        "    for word in unique:\n",
        "        a = 0\n",
        "        b = 0\n",
        "        c = 0\n",
        "        d = 0\n",
        "        #Below will go through each word and count which they fall into.The counters are above   \n",
        "        for line in data:\n",
        "            \n",
        "            if word in line[\"Review\"].lower() and line[\"Safety hazard\"] == 1:\n",
        "                a+=1\n",
        "            \n",
        "            if word in line[\"Review\"].lower() and line[\"Safety hazard\"] == 0:\n",
        "                b+=1\n",
        "\n",
        "            if word not in line[\"Review\"].lower() and line[\"Safety hazard\"] == 1:\n",
        "                c+=1\n",
        "\n",
        "            if word not in line[\"Review\"].lower() and line[\"Safety hazard\"] == 0:\n",
        "                d+=1\n",
        "        #This will generate the relevance the score for the words, if there is an error of denominator of zero, then a relevance score of zero will be used for that word\n",
        "        try:\n",
        "            score = (math.sqrt(a + b + c + d)) * ((a * d) - (c * b)) / math.sqrt((a + b) * (c + d))\n",
        "                \n",
        "        except:\n",
        "            score = 0\n",
        "          \n",
        "        if score >= 4000:\n",
        "\n",
        "            total.append(word)\n",
        "    #Below are the 2D list to train the machine learning models based on relevant words\n",
        "    x = [] \n",
        "    y = []       \n",
        "    for line in data:\n",
        "        inner_list = []\n",
        "\n",
        "        for word in total:\n",
        "\n",
        "            if word in line[\"Review\"].lower():\n",
        "                inner_list.append(1)\n",
        "\n",
        "            if word not in line[\"Review\"].lower():\n",
        "                inner_list.append(0)\n",
        "\n",
        "        x.append(inner_list)\n",
        "        y.append(line[\"Safety hazard\"])\n",
        "\n",
        "\n",
        "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size = 0.2)\n",
        "\n",
        "    #This will print the decision tree model\n",
        "    dt_clf = sklearn.tree.DecisionTreeClassifier()\n",
        "    dt_clf = dt_clf.fit(x_train, y_train)\n",
        "    dt_predictions = dt_clf.predict(x_test)\n",
        "    dt_accuracy = sklearn.metrics.accuracy_score(y_test, dt_predictions)\n",
        "    print(\"Decision Tree accuracy:\", dt_accuracy)\n",
        "\n",
        "    #This will print the k-nearest neighbors model\n",
        "    knn_clf = sklearn.neighbors.KNeighborsClassifier(5)\n",
        "    knn_clf = knn_clf.fit(x_train, y_train)\n",
        "    knn_predictions = knn_clf.predict(x_test)\n",
        "    knn_accuracy = sklearn.metrics.accuracy_score(y_test, knn_predictions)\n",
        "    print(\"k-nearest neighbors accuracy:\", knn_accuracy)\n",
        "\n",
        "    #This will print the neural network model\n",
        "    nn_clf = sklearn.neural_network.MLPClassifier()\n",
        "    nn_clf = nn_clf.fit(x_train, y_train)\n",
        "    nn_predictions = nn_clf.predict(x_test)\n",
        "    nn_accuracy = sklearn.metrics.accuracy_score(y_test, nn_predictions)\n",
        "    print(\"Neural Network accuracy:\", nn_accuracy)\n",
        "\n",
        "    #This will determine the most accurate data and then print the most accurate data from the three models to be saved.\n",
        "    most_accurate = {\"Decision Tree model performed best;\": dt_accuracy, \"k-nearest neighbors model performed best;\": knn_accuracy, \"Neural Network model performed best;\": nn_accuracy}\n",
        "    best = max(most_accurate, key=most_accurate.get)\n",
        "\n",
        "    print(best, \"saved to model.joblib.\")\n",
        "    \n",
        "    #Below will save the most accurate model \n",
        "    most_accurate_save = [dt_accuracy, knn_accuracy, nn_accuracy]\n",
        "    save = max(most_accurate_save)\n",
        "    \n",
        "    if dt_accuracy > knn_accuracy and nn_accuracy:\n",
        "        joblib.dump(dt_clf, \"model.joblib\")\n",
        "\n",
        "    elif knn_accuracy > dt_accuracy and nn_accuracy:\n",
        "        joblib.dump(knn_clf, \"model.joblib\")\n",
        "\n",
        "    elif nn_accuracy > dt_accuracy and knn_accuracy:\n",
        "        joblib.dump(nn_clf, \"model.joblib\")\n",
        "\n",
        "    else:\n",
        "        print(\"Sorry, error saving\")\n",
        "\n",
        "else:\n",
        "    print(\"Sorry, error\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Decision Tree accuracy: 0.85\n",
            "k-nearest neighbors accuracy: 0.85\n",
            "Neural Network accuracy: 0.88\n",
            "Neural Network model performed best; saved to model.joblib.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        }
      ]
    }
  ]
}